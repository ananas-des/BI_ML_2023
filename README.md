# BI_ML_2023

This repository for **Machine Learning Course *Homeworks*** in *Bioinformatics Institute 2023*

## Homework1. *k*-Nearest Neighbors Method

For **Homework1** we tried to implement ***k*-Nearest Neighbors** machine learning algorithm using custom fuctions for classification and model metrics, and comparing their performance with respective functions from `scikit-learn` Python package. This task were coded with basic Python and `pandas` package. For data visualization we used `matplotlib` and `seaborn` packages.

## Homework2. Linear Regression. Gradient descend

For **Homework2** we tried to implement **Linear regression** machine learning algorithms using custom fuctions for regression and binary classification, and using `scikit-learn` Python package. This task were coded with basic Python and `pandas` package. For data visualization, VIF and QQ-plot creation we used `matplotlib`, `seaborn`, and `statsmodels` packages.

## Homework3. Clustering and tSNE

For **Homework3** we tried to implement **Clustering** machine learning algorithms, such as **KMeans**, **Agglomerative Clustering**, and **DBSCAN**, using custom fuctions for Kmeans, and from `scikit-learn` Python package. This task were coded with basic Python and `pandas` package. For data visualization we used `matplotlib`, `seaborn`, and `IPython` packages.

## Homework4. Ensembles

For **Homework4** we tried to implement machine learning algorithms, such as **Decision Tree**, **Random Forest**, **CatBOOST** and many others, using custom fuctions for RandomForest Classification, and from `scikit-learn`, `xgboost`, `lightgbm`, `catboost` Python packages. This task were coded with basic Python and `pandas` package. For data visualization we used `matplotlib` and `seaborn` packages.

## Homework5. kaggle Dota2 Competition

Here some solutions based on `CatBoostClassifier` from `catboost` Python package for **BI_2023** [kaggle](https://www.kaggle.com/competitions/bi-ml-competition-2023/overview) **Dota2 Competition**.

## Homework6. Multiplayer perceptron

For **Homework6** we tried to build **MLP** (multiplayer perceptron) with three multiconnected layers and different activation functions and optimizators using `torch` Python package. For data visualization we used `matplotlib` packages.

## Homework7. Convolutional neural networks (CNN)

For **Homework7** we created custom **convolution function** and tried to reproduce **AlexNet** architecture with *five* convolutional layers and a 2D max pooling for feature extraction. For classification stage, we used two linear fully connected (FC) layers. `ReLU` activation function was used for both purposes. Different convolution, activation and optimization was performed using `pytorch` Python package. For data visualization we used `matplotlib` and `seaborn` packages.
