# BI_ML_2023

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white) ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) ![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white) ![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white) ![SciPy](https://img.shields.io/badge/SciPy-%230C55A5.svg?style=for-the-badge&logo=scipy&logoColor=%white) ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)

This repository for **Machine Learning Course *Homeworks*** in *Bioinformatics Institute 2023*

## Homework1. *k*-Nearest Neighbors Method :tshirt:

For [Homework1](hw1_kNN) we tried to implement ***k*-Nearest Neighbors** machine learning algorithm using custom fuctions for classification and model metrics, and comparing their performance with respective functions from `scikit-learn` Python package. This task were coded with basic Python and `pandas` package. For data visualization we used `matplotlib` and `seaborn` packages.

## Homework2. Linear Regression. Gradient descend :zap:

For [Homework2](hw2_LR) we tried to implement **Linear regression** machine learning algorithms using custom fuctions for regression and binary classification, and using `scikit-learn` Python package. This task were coded with basic Python and `pandas` package. For data visualization, VIF and QQ-plot creation we used `matplotlib`, `seaborn`, and `statsmodels` packages.

## Homework3. Clustering and tSNE :high_brightness:

For [Homework3](hw3_clustering) we tried to implement **Clustering** machine learning algorithms, such as **KMeans**, **Agglomerative Clustering**, and **DBSCAN**, using custom fuctions for Kmeans, and from `scikit-learn` Python package. This task were coded with basic Python and `pandas` package. For data visualization we used `matplotlib`, `seaborn`, and `IPython` packages.

## Homework4. Ensembles :telephone:

For [Homework4](hw4_ensembles) we tried to implement machine learning algorithms, such as **Decision Tree**, **Random Forest**, **CatBOOST** and many others, using custom fuctions for RandomForest Classification, and from `scikit-learn`, `xgboost`, `lightgbm`, `catboost` Python packages. This task were coded with basic Python and `pandas` package. For data visualization we used `matplotlib` and `seaborn` packages.

## Homework5. kaggle Dota2 Competition :goberserk:

[Here](hw5_kaggle) some solutions based on `CatBoostClassifier` from `catboost` Python package for **BI_2023** [kaggle](https://www.kaggle.com/competitions/bi-ml-competition-2023/overview) **Dota2 Competition**.

## Homework6. Multiplayer perceptron :izakaya_lantern:

For [Homework6](hw6_MLP) we tried to build **MLP** (multiplayer perceptron) with three multiconnected layers and different activation functions and optimizators using `torch` Python package. For data visualization we used `matplotlib` packages.

## Homework7. Convolutional neural networks (CNN) :herb:

For [Homework7](hw7_CNN) we created custom **convolution function** and tried to reproduce **AlexNet** architecture with *five* convolutional layers and a 2D max pooling for feature extraction. For classification stage, we used two linear fully connected (FC) layers. `ReLU` activation function was used for both purposes. Different convolution, activation and optimization was performed using `pytorch` Python package. For data visualization we used `matplotlib` and `seaborn` packages.
